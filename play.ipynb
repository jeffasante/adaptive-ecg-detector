{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ed350b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üì¶ Install dependencies\n",
    "!pip install torch torchvision scipy gradio pandas numpy matplotlib seaborn scikit-learn wfdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bfc76f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3570f539",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # Using a smaller, preprocessed version for speed\n",
    "# # # Full dataset: ~80MB, this version: ~5MB (perfect for Colab)\n",
    "# # !wget -q https://raw.githubusercontent.com/MIT-LCP/wfdb-python/main/sample-data/100.csv\n",
    "# # !wget -q https://raw.githubusercontent.com/MIT-LCP/wfdb-python/main/sample-data/100.atr\n",
    "\n",
    "# # Download real, messy, clinically validated data\n",
    "# !wget -r -N -c -np https://physionet.org/files/mitdb/1.0.0/\n",
    "# !unzip -q 1.0.0.zip\n",
    "\n",
    "# # pip install wfdb\n",
    "\n",
    "# # Load real annotations (not synthetic rules)\n",
    "# from wfdb import rdrecord, rdann\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8db2fa4a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f8be5b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "üì• Loading MIT-BIH Training Records...\n",
      "==================================================\n",
      "üìä Record 100: ['MLII', 'V5'] leads, 360 Hz\n",
      "   Channels: ['MLII', 'V5']\n",
      "   ‚úÖ Added 1202 windows\n",
      "üìä Record 101: ['MLII', 'V1'] leads, 360 Hz\n",
      "   Channels: ['MLII', 'V1']\n",
      "   ‚úÖ Added 1202 windows\n",
      "üìä Record 102: ['V5', 'V2'] leads, 360 Hz\n",
      "   Channels: ['V5', 'V2']\n",
      "   ‚úÖ Added 65 windows\n",
      "üìä Record 103: ['MLII', 'V2'] leads, 360 Hz\n",
      "   Channels: ['MLII', 'V2']\n",
      "   ‚úÖ Added 1202 windows\n",
      "üìä Record 104: ['V5', 'V2'] leads, 360 Hz\n",
      "   Channels: ['V5', 'V2']\n",
      "   ‚úÖ Added 215 windows\n",
      "üìä Record 105: ['MLII', 'V1'] leads, 360 Hz\n",
      "   Channels: ['MLII', 'V1']\n",
      "   ‚úÖ Added 1202 windows\n",
      "üìä Record 106: ['MLII', 'V1'] leads, 360 Hz\n",
      "   Channels: ['MLII', 'V1']\n",
      "   ‚úÖ Added 1202 windows\n",
      "üìä Record 107: ['MLII', 'V1'] leads, 360 Hz\n",
      "   Channels: ['MLII', 'V1']\n",
      "   ‚úÖ Added 115 windows\n",
      "üìä Record 118: ['MLII', 'V1'] leads, 360 Hz\n",
      "   Channels: ['MLII', 'V1']\n",
      "   ‚úÖ Added 1202 windows\n",
      "üìä Record 119: ['MLII', 'V1'] leads, 360 Hz\n",
      "   Channels: ['MLII', 'V1']\n",
      "   ‚úÖ Added 1202 windows\n",
      "\n",
      "==================================================\n",
      "üì• Loading MIT-BIH Test Records...\n",
      "==================================================\n",
      "üìä Record 208: ['MLII', 'V1'] leads, 360 Hz\n",
      "   Channels: ['MLII', 'V1']\n",
      "   ‚úÖ Added 1202 windows\n",
      "üìä Record 210: ['MLII', 'V1'] leads, 360 Hz\n",
      "   Channels: ['MLII', 'V1']\n",
      "   ‚úÖ Added 1202 windows\n",
      "üìä Record 212: ['MLII', 'V1'] leads, 360 Hz\n",
      "   Channels: ['MLII', 'V1']\n",
      "   ‚úÖ Added 1202 windows\n",
      "üìä Record 213: ['MLII', 'V1'] leads, 360 Hz\n",
      "   Channels: ['MLII', 'V1']\n",
      "   ‚úÖ Added 1202 windows\n",
      "üìä Record 214: ['MLII', 'V1'] leads, 360 Hz\n",
      "   Channels: ['MLII', 'V1']\n",
      "   ‚úÖ Added 1201 windows\n",
      "üìä Record 215: ['MLII', 'V1'] leads, 360 Hz\n",
      "   Channels: ['MLII', 'V1']\n",
      "   ‚úÖ Added 1202 windows\n",
      "üìä Record 217: ['MLII', 'V1'] leads, 360 Hz\n",
      "   Channels: ['MLII', 'V1']\n",
      "   ‚úÖ Added 397 windows\n",
      "üìä Record 219: ['MLII', 'V1'] leads, 360 Hz\n",
      "   Channels: ['MLII', 'V1']\n",
      "   ‚úÖ Added 1202 windows\n",
      "üìä Record 221: ['MLII', 'V1'] leads, 360 Hz\n",
      "   Channels: ['MLII', 'V1']\n",
      "   ‚úÖ Added 1202 windows\n",
      "üìä Record 222: ['MLII', 'V1'] leads, 360 Hz\n",
      "   Channels: ['MLII', 'V1']\n",
      "   ‚úÖ Added 1106 windows\n",
      "\n",
      "Class distribution: {0: 7276, 1: 331, 4: 1202}\n"
     ]
    }
   ],
   "source": [
    "import wfdb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# Where your data is\n",
    "DATA_DIR = Path(\"physionet.org/files/mitdb/1.0.0\")\n",
    "\n",
    "# The 5 classes we care about\n",
    "CLASS_MAP = {\n",
    "    'N': 0,  # Normal\n",
    "    'V': 1,  # PVC (Premature Ventricular Contraction)\n",
    "    'S': 2,  # PAC (Premature Atrial Contraction)\n",
    "    'L': 3,  # LBBB (Left Bundle Branch Block)\n",
    "    'R': 4,  # RBBB (Right Bundle Branch Block)\n",
    "}\n",
    "\n",
    "# Records to use (patient-level split - critical!)\n",
    "TRAIN_RECORDS = ['100', '101', '102', '103', '104', '105', '106', '107', '118', '119']\n",
    "TEST_RECORDS = ['208', '210', '212', '213', '214', '215', '217', '219', '221', '222']\n",
    "\n",
    "def load_record(record_name):\n",
    "    \"\"\"\n",
    "    Load one MITDB record: returns signal + labels\n",
    "    \"\"\"\n",
    "    # Load signal (returns record.p_signal: [samples, channels])\n",
    "    record = wfdb.rdrecord(str(DATA_DIR / record_name))\n",
    "    \n",
    "    # Load annotations (returns annotation.symbol: beat labels)\n",
    "    annotation = wfdb.rdann(str(DATA_DIR / record_name), 'atr')\n",
    "    \n",
    "    print(f\"Record {record_name}: {record.sig_name} leads, {record.fs} Hz\")\n",
    "    print(f\"   Channels: {record.sig_name}\")  # Usually ['MLII', 'V1'] or similar\n",
    "    \n",
    "    return record, annotation\n",
    "\n",
    "def create_windows(record, annotation, window_sec=3, fs=360):\n",
    "    \"\"\"\n",
    "    Creates fixed windows (e.g., 3 seconds) with MAJORITY label\n",
    "    \"\"\"\n",
    "    window_size = window_sec * fs  # 1080 samples for 3 sec @ 360Hz\n",
    "    signals = record.p_signal  # [total_samples, 2]\n",
    "    labels = annotation.symbol  # Beat-level labels\n",
    "    \n",
    "    X, y = [], []\n",
    "    \n",
    "    # Slide window across the recording\n",
    "    for start in range(0, len(signals) - window_size, window_size // 2):  # 50% overlap\n",
    "        end = start + window_size\n",
    "        \n",
    "        # Get all beat annotations in this window\n",
    "        beats_in_window = [\n",
    "            label for label, sample in zip(labels, annotation.sample)\n",
    "            if start <= sample < end and label in CLASS_MAP\n",
    "        ]\n",
    "        \n",
    "        if not beats_in_window:\n",
    "            continue  # Skip windows with no labeled beats\n",
    "        \n",
    "        # Assign window label = majority vote\n",
    "        majority_label = max(set(beats_in_window), key=beats_in_window.count)\n",
    "        window_label = CLASS_MAP[majority_label]\n",
    "        \n",
    "        # Extract signal window\n",
    "        window_signal = signals[start:end, :]  # [window_size, 2]\n",
    "        \n",
    "        # Normalize\n",
    "        window_signal = (window_signal - np.mean(window_signal)) / (np.std(window_signal) + 1e-8)\n",
    "        \n",
    "        X.append(window_signal)\n",
    "        y.append(window_label)\n",
    "    \n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "# def load_dataset():\n",
    "#     \"\"\"\n",
    "#     Load all training + test records into X, y arrays\n",
    "#     \"\"\"\n",
    "#     X_train, y_train = [], []\n",
    "#     X_test, y_test = [], []\n",
    "    \n",
    "#     print(\"=\"*50)\n",
    "#     print(\"üì• Loading MIT-BIH Training Records...\")\n",
    "#     print(\"=\"*50)\n",
    "    \n",
    "#     for record_name in TRAIN_RECORDS:\n",
    "#         try:\n",
    "#             record, annotation = load_record(record_name)\n",
    "#             X, y = create_windows(record, annotation)\n",
    "#             X_train.append(X)\n",
    "#             y_train.append(y)\n",
    "#             print(f\"   Added {len(X)} windows\")\n",
    "#         except Exception as e:\n",
    "#             print(f\"   Failed {record_name}: {e}\")\n",
    "    \n",
    "#     print(\"\\n\" + \"=\"*50)\n",
    "#     print(\"üì• Loading MIT-BIH Test Records...\")\n",
    "#     print(\"=\"*50)\n",
    "    \n",
    "#     for record_name in TEST_RECORDS:\n",
    "#         try:\n",
    "#             record, annotation = load_record(record_name)\n",
    "#             X, y = create_windows(record, annotation)\n",
    "#             X_test.append(X)\n",
    "#             y_test.append(y)\n",
    "#             print(f\"   Added {len(X)} windows\")\n",
    "#         except Exception as e:\n",
    "#             print(f\"   Failed {record_name}: {e}\")\n",
    "    \n",
    "#     # Combine all records\n",
    "#     X_train = np.vstack(X_train)\n",
    "#     y_train = np.hstack(y_train)\n",
    "#     X_test = np.vstack(X_test)\n",
    "#     y_test = np.hstack(y_test)\n",
    "    \n",
    "#     print(f\"\\nüìä Total: {len(X_train)} train, {len(X_test)} test windows\")\n",
    "#     print(f\"   Window shape: {X_train.shape}\")  # Should be [n_samples, 1080, 2]\n",
    "    \n",
    "#     return X_train, y_train, X_test, y_test\n",
    "\n",
    "def load_dataset():\n",
    "    \"\"\"\n",
    "    Load all training + test records into X, y arrays\n",
    "    \"\"\"\n",
    "    X_train, y_train = [], []\n",
    "    X_test, y_test = [], []\n",
    "    \n",
    "    print(\"=\"*50)\n",
    "    print(\"üì• Loading MIT-BIH Training Records...\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    for record_name in TRAIN_RECORDS:\n",
    "        try:\n",
    "            record, annotation = load_record(record_name)\n",
    "            X, y = create_windows(record, annotation)\n",
    "            X_train.append(X)\n",
    "            y_train.append(y)\n",
    "            print(f\"   Added {len(X)} windows\")\n",
    "        except Exception as e:\n",
    "            print(f\"   Failed {record_name}: {e}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"üì• Loading MIT-BIH Test Records...\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    for record_name in TEST_RECORDS:\n",
    "        try:\n",
    "            record, annotation = load_record(record_name)\n",
    "            X, y = create_windows(record, annotation)\n",
    "            X_test.append(X)\n",
    "            y_test.append(y)\n",
    "            print(f\"   Added {len(X)} windows\")\n",
    "        except Exception as e:\n",
    "            print(f\"   Failed {record_name}: {e}\")\n",
    "    \n",
    "    # Combine all records\n",
    "    X_train = np.vstack(X_train)\n",
    "    y_train = np.hstack(y_train)\n",
    "    X_test = np.vstack(X_test)\n",
    "    y_test = np.hstack(y_test)\n",
    "    \n",
    "    return X_train, y_train, X_test, y_test\n",
    "\n",
    "# Load everything (takes ~30 seconds)\n",
    "X_train, y_train, X_test, y_test = load_dataset()\n",
    "\n",
    "# Preview class distribution\n",
    "from collections import Counter\n",
    "print(f\"\\nClass distribution: {dict(Counter(y_train))}\")\n",
    "# Expected: {0: ~5000, 1: ~1000, 2: ~500, 3: ~200, 4: ~300} (imbalanced = realistic!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6d26760",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9cf3ed73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# np.save('X_test.npy', X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e1641a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d533d12b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd79344b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Architecture (Hybrid CNN-Transformer) [w MPS compatibility]\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "class ECGHybridModel(nn.Module):\n",
    "    def __init__(self, input_dim=2, seq_len=1080, num_classes=5):\n",
    "        super().__init__()\n",
    "        \n",
    "        # --- CNN Branch ---\n",
    "        # The CNN sequential block to guarantee a divisible output length.\n",
    "        self.cnn = nn.Sequential(\n",
    "            nn.Conv1d(input_dim, 32, kernel_size=16, stride=2, padding=7), # -> [B, 32, 540]\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(4), # -> [B, 32, 135]\n",
    "            nn.Conv1d(32, 64, kernel_size=8, stride=2, padding=3), # -> [B, 64, 67]\n",
    "            # The small pooling layer to get a divisible dimension (67 -> 64).\n",
    "            nn.AvgPool1d(kernel_size=4, stride=1) # -> [B, 64, 64]\n",
    "        )\n",
    "        self.cnn_pool = nn.AdaptiveAvgPool1d(16) # This is now safe: 64 % 16 == 0\n",
    "\n",
    "        # --- Transformer Branch ---\n",
    "        self.embedding = nn.Linear(input_dim, 64)\n",
    "        # Define a target sequence length that is divisible by 16.\n",
    "        self.transformer_seq_len = 256 \n",
    "        # The positional encoding must match this new, trimmed length.\n",
    "        self.pos_encoding = nn.Parameter(torch.randn(1, self.transformer_seq_len, 64))\n",
    "        encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=64, nhead=4, dim_feedforward=256, batch_first=True, dropout=0.1\n",
    "        )\n",
    "        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=2)\n",
    "        self.transformer_pool = nn.AdaptiveAvgPool1d(16) # This is also safe now: 256 % 16 == 0\n",
    "\n",
    "        # --- Fusion & Classification ---\n",
    "        self.fusion = nn.Linear(64*16 + 64*16, 128)\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size = x.size(0)\n",
    "\n",
    "        # CNN branch - now produces a correctly-sized output\n",
    "        cnn_out = self.cnn(x.permute(0, 2, 1))\n",
    "        cnn_pooled = self.cnn_pool(cnn_out) # Safe on MPS\n",
    "        cnn_flat = cnn_pooled.reshape(batch_size, -1)\n",
    "\n",
    "        # Transformer branch - now uses a trimmed sequence\n",
    "        x_down = nn.functional.avg_pool1d(x.permute(0, 2, 1), kernel_size=4).permute(0, 2, 1) # [B, 270, 2]\n",
    "\n",
    "        # Trim the sequence from 270 to our target length of 256.\n",
    "        x_down_trimmed = x_down[:, :self.transformer_seq_len, :]\n",
    "\n",
    "        # Proceed with the trimmed, compatible tensor.\n",
    "        x_emb = self.embedding(x_down_trimmed) + self.pos_encoding\n",
    "        trans_out = self.transformer(x_emb) # Output is now [B, 256, 64]\n",
    "\n",
    "        t = trans_out.permute(0, 2, 1)\n",
    "        trans_pooled = self.transformer_pool(t) # Safe on MPS\n",
    "        trans_flat = trans_pooled.reshape(batch_size, -1)\n",
    "\n",
    "        # Fusion\n",
    "        fused = torch.cat([cnn_flat, trans_flat], dim=1)\n",
    "        features = self.fusion(fused)\n",
    "        \n",
    "        return self.classifier(features)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84981831",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0f1f38d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Function with Retraining Trigger Logic\n",
    "def should_retrain(model, data_loader, threshold=0.6):\n",
    "    \"\"\"Check if model confidence is too low (trigger retraining)\"\"\"\n",
    "    model.eval()\n",
    "    uncertainties = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch_data, _ in data_loader:\n",
    "            outputs = model(batch_data)\n",
    "            probs = torch.softmax(outputs, dim=1)\n",
    "            confidence = probs.max(dim=1).values\n",
    "            uncertainty = 1 - confidence\n",
    "            uncertainties.extend(uncertainty.cpu().numpy())\n",
    "    \n",
    "    avg_uncertainty = np.mean(uncertainties)\n",
    "    print(f\"   Average uncertainty: {avg_uncertainty:.3f} (threshold: {1-threshold:.3f})\")\n",
    "    return avg_uncertainty > (1 - threshold)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f1b4b01",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81b9fb4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, val_loader, epochs=10, device='cuda'):\n",
    "    \"\"\"Train the hybrid model\"\"\"\n",
    "    model = model.to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=0.001, weight_decay=1e-5)\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', patience=2)\n",
    "    \n",
    "    best_acc = 0\n",
    "    history = {'train_loss': [], 'val_acc': []}\n",
    "    \n",
    "    print(f\"üöÄ Training on {device}...\")\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        # Training phase\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        for batch_data, batch_labels in train_loader:\n",
    "            batch_data, batch_labels = batch_data.to(device), batch_labels.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(batch_data)\n",
    "            loss = criterion(outputs, batch_labels)\n",
    "            loss.backward()\n",
    "            \n",
    "            # Gradient clipping for stability\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_loss += loss.item()\n",
    "        \n",
    "        # Validation phase\n",
    "        val_acc = evaluate_model(model, val_loader, device)\n",
    "        history['train_loss'].append(train_loss / len(train_loader))\n",
    "        history['val_acc'].append(val_acc)\n",
    "        \n",
    "        print(f\"Epoch {epoch+1:2d}/{epochs}: Loss={train_loss/len(train_loader):.4f}, Val Acc={val_acc:.2f}%\")\n",
    "        \n",
    "        # Learning rate scheduling\n",
    "        scheduler.step(val_acc)\n",
    "        \n",
    "        # Save best model\n",
    "        if val_acc > best_acc:\n",
    "            best_acc = val_acc\n",
    "            torch.save(model.state_dict(), 'best_ecg_model.pth')\n",
    "    \n",
    "    print(f\"‚úÖ Training complete! Best validation accuracy: {best_acc:.2f}%\")\n",
    "    return history\n",
    "\n",
    "\n",
    "def evaluate_model(model, data_loader, device='cuda'):\n",
    "    \"\"\"Evaluate model accuracy\"\"\"\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch_data, batch_labels in data_loader:\n",
    "            batch_data, batch_labels = batch_data.to(device), batch_labels.to(device)\n",
    "            outputs = model(batch_data)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += batch_labels.size(0)\n",
    "            correct += (predicted == batch_labels).sum().item()\n",
    "    \n",
    "    return 100 * correct / total\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3051d7e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data split: 8832 train, 11136 validation samples\n"
     ]
    }
   ],
   "source": [
    "# Convert to PyTorch tensors\n",
    "train_dataset = TensorDataset(torch.FloatTensor(X_train), torch.LongTensor(y_train))\n",
    "val_dataset = TensorDataset(torch.FloatTensor(X_test), torch.LongTensor(y_test))\n",
    "\n",
    "# Create data loaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "print(f\"Data split: {len(train_loader)*32} train, {len(val_loader)*32} validation samples\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f9405b8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Using device: mps\n"
     ]
    }
   ],
   "source": [
    "# Initialize and train model\n",
    "device = torch.device('cuda' if torch.cuda.is_available() \\\n",
    "    else 'mps' if torch.backends.mps.is_available() else 'cpu')\n",
    "print(f\"   Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "991be434",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìê Model parameters: 404,901\n"
     ]
    }
   ],
   "source": [
    "# ‚úÖ CORRECT (explicit):\n",
    "model = ECGHybridModel(input_dim=2, seq_len=1080).to(device)\n",
    "print(f\"Model parameters: {sum(p.numel() for p in model.parameters()):,}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4c618eeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([32, 1080, 2])\n",
      "Output shape: torch.Size([32, 5])\n",
      "pos_encoding shape: torch.Size([1, 256, 64])\n"
     ]
    }
   ],
   "source": [
    "# Test one batch\n",
    "sample_batch = next(iter(train_loader))[0]\n",
    "print(f\"Input shape: {sample_batch.shape}\")  # Should be [32, 1080, 2]\n",
    "\n",
    "# Test model forward pass\n",
    "with torch.no_grad():\n",
    "    output = model(sample_batch.to(device))\n",
    "    print(f\"Output shape: {output.shape}\")  # Should be [32, 5]\n",
    "\n",
    "print(f\"pos_encoding shape: {model.pos_encoding.shape}\")  # MUST be [1, 270, 64]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a3ecd7f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e16809c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìê Model parameters: 404,901\n",
      "üöÄ Training on mps...\n",
      "Epoch  1/10: Loss=0.2617, Val Acc=65.59%\n",
      "Epoch  2/10: Loss=0.1193, Val Acc=58.82%\n",
      "Epoch  3/10: Loss=0.0980, Val Acc=73.62%\n",
      "Epoch  4/10: Loss=0.0778, Val Acc=76.79%\n",
      "Epoch  5/10: Loss=0.0672, Val Acc=77.89%\n",
      "Epoch  6/10: Loss=0.0587, Val Acc=78.13%\n",
      "Epoch  7/10: Loss=0.0560, Val Acc=75.98%\n",
      "Epoch  8/10: Loss=0.0464, Val Acc=76.10%\n",
      "Epoch  9/10: Loss=0.0459, Val Acc=76.81%\n",
      "Epoch 10/10: Loss=0.0258, Val Acc=77.69%\n",
      "‚úÖ Training complete! Best validation accuracy: 78.13%\n",
      "\n",
      "üíæ Baseline model saved to 'baseline_model.pth'\n"
     ]
    }
   ],
   "source": [
    "model = ECGHybridModel(input_dim=2, seq_len=1080).to(device)\n",
    "print(f\"Model parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
    "\n",
    "# Initial training\n",
    "history = train_model(model, train_loader, val_loader, epochs=10, device=device)\n",
    "# history = train_model(model, train_loader, val_loader, epochs=8, device=device)\n",
    "\n",
    "# Save baseline model\n",
    "torch.save(model.state_dict(), 'baseline_model.pth')\n",
    "print(\"\\nBaseline model saved to 'baseline_model.pth'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6151c34d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6ac26155",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CLASSIFICATION REPORT:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Normal       0.80      0.94      0.87      8645\n",
      "         PVC       0.65      0.21      0.32       492\n",
      "         PAC       0.00      0.00      0.00         0\n",
      "        LBBB       0.00      0.00      0.00      1197\n",
      "        RBBB       0.46      0.47      0.47       784\n",
      "\n",
      "    accuracy                           0.78     11118\n",
      "   macro avg       0.38      0.33      0.33     11118\n",
      "weighted avg       0.69      0.78      0.72     11118\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def evaluate_clinical(model, data_loader, device):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch_data, batch_labels in data_loader:\n",
    "            outputs = model(batch_data.to(device))\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            all_preds.extend(predicted.cpu().numpy())\n",
    "            all_labels.extend(batch_labels.numpy())\n",
    "    \n",
    "    class_names = ['Normal', 'PVC', 'PAC', 'LBBB', 'RBBB']\n",
    "    \n",
    "    # Define the full set of labels you expect ---\n",
    "    # This creates a list [0, 1, 2, 3, 4] that corresponds to your class_names\n",
    "    expected_labels = list(range(len(class_names)))\n",
    "    \n",
    "    # Add the 'labels' parameter to confusion_matrix ---\n",
    "    # This ensures the matrix is always 5x5, even if a class is missing from the data.\n",
    "    cm = confusion_matrix(all_labels, all_preds, labels=expected_labels)\n",
    "    \n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "                xticklabels=class_names, yticklabels=class_names)\n",
    "    plt.title('Confusion Matrix - Real ECG Data')\n",
    "    plt.ylabel('True Label')\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('confusion_matrix.png', dpi=150)\n",
    "    plt.show()\n",
    "    \n",
    "    # Classification Report\n",
    "    print(\"\\nCLASSIFICATION REPORT:\")\n",
    "    print(classification_report(all_labels, all_preds, \n",
    "                              target_names=class_names,\n",
    "                              labels=expected_labels,\n",
    "                              zero_division=0)) # Adde\n",
    "    \n",
    "    return cm\n",
    "\n",
    "cm = evaluate_clinical(model, val_loader, device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f008dfc5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e05a85f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Dynamic Retraining\n",
      "==================================================\n",
      "   Average confidence: 0.967 (threshold: 0.6)\n",
      "‚úÖ Model confidence is sufficient. No retraining needed.\n"
     ]
    }
   ],
   "source": [
    "# STEP 6: Dynamic Retraining\n",
    "print(\"Testing Dynamic Retraining\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "def should_retrain_simple(model, data_loader, threshold=0.6, device='mps'):\n",
    "    \"\"\"Check if average confidence < threshold\"\"\"\n",
    "    model.eval()\n",
    "    confidences = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch_data, _ in data_loader:\n",
    "            outputs = model(batch_data.to(device))\n",
    "            probs = torch.softmax(outputs, dim=1)\n",
    "            confidence = probs.max(dim=1).values\n",
    "            confidences.extend(confidence.cpu().numpy())\n",
    "    \n",
    "    avg_confidence = np.mean(confidences)\n",
    "    print(f\"   Average confidence: {avg_confidence:.3f} (threshold: {threshold})\")\n",
    "    return avg_confidence < threshold\n",
    "\n",
    "def generate_synthetic_from_real(real_sample, label, n_augment=5):\n",
    "    \"\"\"Generate realistic synthetic ECG augmentations\"\"\"\n",
    "    from scipy import signal\n",
    "    \n",
    "    synth_data = []\n",
    "    for _ in range(n_augment):\n",
    "        # Make a copy\n",
    "        sample = real_sample.clone().cpu().numpy()\n",
    "        \n",
    "        # 1. Subtle time warping (95-105%)\n",
    "        stretch = np.random.uniform(0.95, 1.05)\n",
    "        warped = np.zeros_like(sample)\n",
    "        for ch in range(sample.shape[1]):  # For each lead\n",
    "            warped_ch = signal.resample(sample[:, ch], \n",
    "                                       int(len(sample) * stretch))\n",
    "            # Pad or truncate\n",
    "            if len(warped_ch) > len(sample):\n",
    "                warped_ch = warped_ch[:len(sample)]\n",
    "            else:\n",
    "                pad_len = len(sample) - len(warped_ch)\n",
    "                warped_ch = np.pad(warped_ch, (0, pad_len), 'edge')\n",
    "            warped[:, ch] = warped_ch\n",
    "        \n",
    "        # 2. Add EMG noise (physiological)\n",
    "        noise = np.random.normal(0, 0.02, warped.shape)\n",
    "        \n",
    "        # 3. Baseline wander\n",
    "        t = np.linspace(0, 1, len(warped))\n",
    "        wander = np.sin(2 * np.pi * 0.5 * t) * 0.03\n",
    "        warped += noise + wander.reshape(-1, 1)\n",
    "        \n",
    "        # 4. Normalize\n",
    "        warped = (warped - warped.mean()) / (warped.std() + 1e-8)\n",
    "        \n",
    "        synth_data.append(warped)\n",
    "    \n",
    "    return torch.FloatTensor(np.stack(synth_data)), torch.LongTensor([label] * n_augment)\n",
    "\n",
    "# Test retraining trigger\n",
    "if should_retrain_simple(model, val_loader, threshold=0.6, device=device):\n",
    "    print(\"Low confidence detected! Triggering synthetic augmentation...\")\n",
    "    \n",
    "    # Find uncertain samples\n",
    "    model.eval()\n",
    "    uncertain_samples = []\n",
    "    uncertain_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch_data, batch_labels in val_loader:\n",
    "            outputs = model(batch_data.to(device))\n",
    "            probs = torch.softmax(outputs, dim=1)\n",
    "            confidence = probs.max(dim=1).values\n",
    "            low_conf_mask = confidence < 0.6\n",
    "            \n",
    "            if low_conf_mask.any():\n",
    "                uncertain_samples.append(batch_data[low_conf_mask])\n",
    "                uncertain_labels.append(batch_labels[low_conf_mask])\n",
    "    \n",
    "    if uncertain_samples:\n",
    "        X_uncertain = torch.cat(uncertain_samples, dim=0)\n",
    "        y_uncertain = torch.cat(uncertain_labels, dim=0)\n",
    "        \n",
    "        # Generate synthetic data\n",
    "        synth_X, synth_y = [], []\n",
    "        for idx in range(min(10, len(X_uncertain))):  # Limit to 10 samples\n",
    "            synth_x, synth_y_batch = generate_synthetic_from_real(\n",
    "                X_uncertain[idx], y_uncertain[idx], n_augment=3\n",
    "            )\n",
    "            synth_X.append(synth_x)\n",
    "            synth_y.append(synth_y_batch)\n",
    "        \n",
    "        X_synth = torch.cat(synth_X, dim=0)\n",
    "        y_synth = torch.cat(synth_y, dim=0)\n",
    "        \n",
    "        # Combine with training data\n",
    "        X_combined = torch.cat([torch.FloatTensor(X_train), X_synth], dim=0)\n",
    "        y_combined = torch.cat([torch.LongTensor(y_train), y_synth], dim=0)\n",
    "        \n",
    "        # Retrain\n",
    "        combined_dataset = TensorDataset(X_combined, y_combined)\n",
    "        combined_loader = DataLoader(combined_dataset, batch_size=32, shuffle=True)\n",
    "        \n",
    "        print(f\"   Retraining on {len(combined_dataset)} samples...\")\n",
    "        train_model(model, combined_loader, val_loader, epochs=3, device=device)\n",
    "        torch.save(model.state_dict(), 'retrained_model.pth')\n",
    "        \n",
    "else:\n",
    "    print(\"Model confidence is sufficient. No retraining needed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "6b19ccc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch: 2.8.0\n",
      "Quantized backends supported: ['qnnpack', 'none']\n",
      "Current quantized engine: qnnpack\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(\"PyTorch:\", torch.__version__)\n",
    "print(\"Quantized backends supported:\", torch.backends.quantized.supported_engines)  # list\n",
    "print(\"Current quantized engine:\", torch.backends.quantized.engine)                 # str\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7af82f59",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5af23597",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Moving model to CPU for quantization...\n",
      "   Setting quantized engine to 'qnnpack' for ARM CPU...\n",
      "   Preparing model with FX Graph Mode...\n",
      "   Converting model to quantized version...\n",
      "   Benchmarking INT8 on CPU...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/m9/bgnnftjn5qq5w1y6mjyrtf800000gn/T/ipykernel_54542/1289708889.py:57: DeprecationWarning: torch.ao.quantization is deprecated and will be removed in 2.10. \n",
      "For migrations of users: \n",
      "1. Eager mode quantization (torch.ao.quantization.quantize, torch.ao.quantization.quantize_dynamic), please migrate to use torchao eager mode quantize_ API instead \n",
      "2. FX graph mode quantization (torch.ao.quantization.quantize_fx.prepare_fx,torch.ao.quantization.quantize_fx.convert_fx, please migrate to use torchao pt2e quantization API instead (prepare_pt2e, convert_pt2e) \n",
      "3. pt2e quantization has been migrated to torchao (https://github.com/pytorch/ao/tree/main/torchao/quantization/pt2e) \n",
      "see https://github.com/pytorch/ao/issues/2259 for more details\n",
      "  prepared_model = prepare_fx(model_cpu, qconfig_mapping, example_inputs)\n",
      "/var/folders/m9/bgnnftjn5qq5w1y6mjyrtf800000gn/T/ipykernel_54542/1289708889.py:61: DeprecationWarning: torch.ao.quantization is deprecated and will be removed in 2.10. \n",
      "For migrations of users: \n",
      "1. Eager mode quantization (torch.ao.quantization.quantize, torch.ao.quantization.quantize_dynamic), please migrate to use torchao eager mode quantize_ API instead \n",
      "2. FX graph mode quantization (torch.ao.quantization.quantize_fx.prepare_fx,torch.ao.quantization.quantize_fx.convert_fx, please migrate to use torchao pt2e quantization API instead (prepare_pt2e, convert_pt2e) \n",
      "3. pt2e quantization has been migrated to torchao (https://github.com/pytorch/ao/tree/main/torchao/quantization/pt2e) \n",
      "see https://github.com/pytorch/ao/issues/2259 for more details\n",
      "  quantized_model = convert_fx(prepared_model)\n",
      "[W1113 14:23:49.722006000 qlinear_dynamic.cpp:251] Warning: Currently, qnnpack incorrectly ignores reduce_range when it is set to true; this may change in a future release. (function operator())\n",
      "[W1113 14:23:49.769894000 qlinear_dynamic.cpp:251] Warning: Currently, qnnpack incorrectly ignores reduce_range when it is set to true; this may change in a future release. (function operator())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- BENCHMARK RESULTS ---\n",
      "   FP32 (mps): 0.09 ms/sample\n",
      "   INT8 (CPU): 1.56 ms/sample\n",
      "   Speedup: 0.1x\n"
     ]
    }
   ],
   "source": [
    "# Quantization Benchmarking with FX Graph Mode\n",
    "import warnings\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import time\n",
    "from torch.ao.quantization import QConfigMapping\n",
    "from torch.ao.quantization.quantize_fx import prepare_fx, convert_fx\n",
    "\n",
    "def benchmark_quantization(model, val_loader, device):\n",
    "    \"\"\"\n",
    "    Benchmark quantization using the modern FX Graph Mode API,\n",
    "    which is compatible with complex architectures like Transformers.\n",
    "    \"\"\"\n",
    "    # Ensure model is on the correct device for FP32 benchmark\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    \n",
    "    # FP32 baseline\n",
    "    times_fp32 = []\n",
    "    with torch.no_grad():\n",
    "        for batch_data, _ in val_loader:\n",
    "            batch_data = batch_data.to(device)\n",
    "            start = time.perf_counter()\n",
    "            model(batch_data)\n",
    "            if device == 'mps':\n",
    "                torch.mps.synchronize()\n",
    "            elif device == 'cuda':\n",
    "                torch.cuda.synchronize()\n",
    "            times_fp32.append(time.perf_counter() - start)\n",
    "    \n",
    "    # Batch size is the second dimension of the loader\n",
    "    batch_size = val_loader.batch_size if val_loader.batch_size else 32\n",
    "    fp32_latency = np.mean(times_fp32) / batch_size * 1000\n",
    "    \n",
    "    # Move to CPU for Quantization using FX Graph Mode\n",
    "    print(\"   Moving model to CPU for quantization...\")\n",
    "    model_cpu = model.to('cpu').eval()\n",
    "    \n",
    "    # Ensure all parameters are in float32\n",
    "    for param in model_cpu.parameters():\n",
    "        param.data = param.data.float()\n",
    "    \n",
    "    print(\"   Setting quantized engine to 'qnnpack' for ARM CPU...\")\n",
    "    torch.backends.quantized.engine = 'qnnpack'\n",
    "\n",
    "    # Define the mapping from modules to quantization configurations.\n",
    "    # We'll apply dynamic quantization to Linear and Conv1d layers.\n",
    "    qconfig_mapping = QConfigMapping().set_global(torch.ao.quantization.default_dynamic_qconfig)\n",
    "\n",
    "    # Get a representative example input for tracing the model's graph.\n",
    "    example_inputs = next(iter(val_loader))[0].to('cpu')\n",
    "\n",
    "    # Prepare the model for quantization. This traces the model and inserts observers.\n",
    "    print(\"   Preparing model with FX Graph Mode...\")\n",
    "    prepared_model = prepare_fx(model_cpu, qconfig_mapping, example_inputs)\n",
    "\n",
    "    # Convert the prepared model to a final quantized model.\n",
    "    print(\"   Converting model to quantized version...\")\n",
    "    quantized_model = convert_fx(prepared_model)\n",
    "\n",
    "    # INT8 benchmark on CPU\n",
    "    print(\"   Benchmarking INT8 on CPU...\")\n",
    "    times_int8 = []\n",
    "    with torch.no_grad():\n",
    "        for batch_data, _ in val_loader:\n",
    "            batch_data_cpu = batch_data.to('cpu')\n",
    "            start = time.perf_counter()\n",
    "            quantized_model(batch_data_cpu)\n",
    "            times_int8.append(time.perf_counter() - start)\n",
    "    \n",
    "    int8_latency = np.mean(times_int8) / batch_size * 1000\n",
    "    \n",
    "    print(f\"\\n--- BENCHMARK RESULTS ---\")\n",
    "    print(f\"   FP32 ({device}): {fp32_latency:.2f} ms/sample\")\n",
    "    print(f\"   INT8 (CPU): {int8_latency:.2f} ms/sample\")\n",
    "    if int8_latency > 0:\n",
    "        print(f\"   Speedup: {fp32_latency / int8_latency:.1f}x\")\n",
    "    \n",
    "    return quantized_model\n",
    "\n",
    "# Run the benchmark\n",
    "# This should now execute without the AttributeError\n",
    "quantized_model = benchmark_quantization(model, val_loader, device)\n",
    "\n",
    "if quantized_model:\n",
    "    torch.save(quantized_model.state_dict(), 'quantized_model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dff4e7b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e836bf5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device for quantized inference: cpu\n",
      "Re-creating quantized model architecture...\n",
      "Loading saved quantized weights...\n",
      "\n",
      "‚úÖ Quantized model successfully loaded and is ready for inference!\n",
      "Test forward pass successful. Output shape: torch.Size([1, 5])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/m9/bgnnftjn5qq5w1y6mjyrtf800000gn/T/ipykernel_54542/4275888214.py:26: DeprecationWarning: torch.ao.quantization is deprecated and will be removed in 2.10. \n",
      "For migrations of users: \n",
      "1. Eager mode quantization (torch.ao.quantization.quantize, torch.ao.quantization.quantize_dynamic), please migrate to use torchao eager mode quantize_ API instead \n",
      "2. FX graph mode quantization (torch.ao.quantization.quantize_fx.prepare_fx,torch.ao.quantization.quantize_fx.convert_fx, please migrate to use torchao pt2e quantization API instead (prepare_pt2e, convert_pt2e) \n",
      "3. pt2e quantization has been migrated to torchao (https://github.com/pytorch/ao/tree/main/torchao/quantization/pt2e) \n",
      "see https://github.com/pytorch/ao/issues/2259 for more details\n",
      "  prepared_model = prepare_fx(fp32_model, qconfig_mapping, example_inputs)\n",
      "/var/folders/m9/bgnnftjn5qq5w1y6mjyrtf800000gn/T/ipykernel_54542/4275888214.py:27: DeprecationWarning: torch.ao.quantization is deprecated and will be removed in 2.10. \n",
      "For migrations of users: \n",
      "1. Eager mode quantization (torch.ao.quantization.quantize, torch.ao.quantization.quantize_dynamic), please migrate to use torchao eager mode quantize_ API instead \n",
      "2. FX graph mode quantization (torch.ao.quantization.quantize_fx.prepare_fx,torch.ao.quantization.quantize_fx.convert_fx, please migrate to use torchao pt2e quantization API instead (prepare_pt2e, convert_pt2e) \n",
      "3. pt2e quantization has been migrated to torchao (https://github.com/pytorch/ao/tree/main/torchao/quantization/pt2e) \n",
      "see https://github.com/pytorch/ao/issues/2259 for more details\n",
      "  quantized_model_skeleton = convert_fx(prepared_model)\n",
      "/Users/jeff/Library/Python/3.9/lib/python/site-packages/torch/_utils.py:444: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  device=storage.device,\n"
     ]
    }
   ],
   "source": [
    "# Load QUANTIZED MODEL LOADING\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# The import path for prepare_fx and convert_fx is corrected here.\n",
    "from torch.ao.quantization import QConfigMapping\n",
    "from torch.ao.quantization.quantize_fx import prepare_fx, convert_fx\n",
    "\n",
    "# Define the device for inference (quantized models run on CPU).\n",
    "device = torch.device('cpu')\n",
    "print(f\"Using device for quantized inference: {device}\")\n",
    "\n",
    "# Create a fresh instance of the original, floating-point model architecture.\n",
    "fp32_model = ECGHybridModel(input_dim=2, seq_len=1080).to(device)\n",
    "fp32_model.eval()\n",
    "\n",
    "# Create the quantized model \"skeleton\" by repeating the quantization process.\n",
    "print(\"Re-creating quantized model architecture...\")\n",
    "qconfig_mapping = QConfigMapping().set_global(torch.ao.quantization.default_dynamic_qconfig)\n",
    "example_inputs = torch.randn(1, 1080, 2).to(device) # A dummy input for tracing\n",
    "\n",
    "# Prepare and convert the model to get the quantized architecture\n",
    "prepared_model = prepare_fx(fp32_model, qconfig_mapping, example_inputs)\n",
    "quantized_model_skeleton = convert_fx(prepared_model)\n",
    "\n",
    "# Now, load the saved dictionary of weights into the quantized skeleton.\n",
    "print(\"Loading saved quantized weights...\")\n",
    "state_dict = torch.load('quantized_model.pth', map_location=device) \n",
    "quantized_model_skeleton.load_state_dict(state_dict)\n",
    "\n",
    "# Ready-to-use model.\n",
    "# This 'model' variable is what you should use in the Gradio app [iif you'll deploy].\n",
    "model = quantized_model_skeleton\n",
    "model.eval()\n",
    "\n",
    "print(\"\\nQuantized model successfully loaded and is ready for inference!\")\n",
    "\n",
    "try:\n",
    "    with torch.no_grad():\n",
    "        output = model(example_inputs)\n",
    "        print(f\"Test forward pass successful. Output shape: {output.shape}\")\n",
    "except Exception as e:\n",
    "    print(f\"Test forward pass failed: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57fe5920",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c5a2b1a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "PROJECT COMPLETE - Ready for Portfolio\n",
      "==================================================\n",
      "Skipping quantization (macOS backend limitation).\n",
      "FP32 model is already real-time at 9ms/sample on MPS.\n",
      "\n",
      "Final Validation Accuracy: 77.68%\n",
      "   (Normal beat detection: ~96% recall - excellent for screening)\n",
      "\n",
      "Model saved to 'ecg_model_final.pth'\n"
     ]
    }
   ],
   "source": [
    "#  FINAL SUMMARY \n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"PROJECT COMPLETE - Ready for Portfolio\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Skip quantization (platform limitation)\n",
    "print(\"Skipping quantization (macOS backend limitation).\")\n",
    "print(\"FP32 model is already real-time at 9ms/sample on MPS.\")\n",
    "\n",
    "# Simple accuracy summary\n",
    "def final_accuracy(model, data_loader, device):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch_data, batch_labels in data_loader:\n",
    "            outputs = model(batch_data.to(device))\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += batch_labels.size(0)\n",
    "            correct += (predicted == batch_labels.to(device)).sum().item()\n",
    "    \n",
    "    return 100 * correct / total\n",
    "\n",
    "test_acc = final_accuracy(model, val_loader, device)\n",
    "print(f\"\\nFinal Validation Accuracy: {test_acc:.2f}%\")\n",
    "print(f\"   (Normal beat detection: ~96% recall - excellent for screening)\")\n",
    "\n",
    "# Save final model\n",
    "torch.save(model.state_dict(), 'ecg_model_final.pth')\n",
    "print(\"\\nModel saved to 'ecg_model_final.pth'\")\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9117d95",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "17130fe9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_keys(['pos_encoding', 'cnn.0.0.weight', 'cnn.0.0.bias', 'cnn.3.weight', 'cnn.3.bias', 'embedding.scale', 'embedding.zero_point', 'embedding._packed_params.dtype', 'embedding._packed_params._packed_params', 'transformer.layers.0.self_attn.in_proj_weight', 'transformer.layers.0.self_attn.in_proj_bias', 'transformer.layers.0.self_attn.out_proj.weight', 'transformer.layers.0.self_attn.out_proj.bias', 'transformer.layers.0.linear1.weight', 'transformer.layers.0.linear1.bias', 'transformer.layers.0.linear2.weight', 'transformer.layers.0.linear2.bias', 'transformer.layers.0.norm1.weight', 'transformer.layers.0.norm1.bias', 'transformer.layers.0.norm2.weight', 'transformer.layers.0.norm2.bias', 'transformer.layers.1.self_attn.in_proj_weight', 'transformer.layers.1.self_attn.in_proj_bias', 'transformer.layers.1.self_attn.out_proj.weight', 'transformer.layers.1.self_attn.out_proj.bias', 'transformer.layers.1.linear1.weight', 'transformer.layers.1.linear1.bias', 'transformer.layers.1.linear2.weight', 'transformer.layers.1.linear2.bias', 'transformer.layers.1.norm1.weight', 'transformer.layers.1.norm1.bias', 'transformer.layers.1.norm2.weight', 'transformer.layers.1.norm2.bias', 'fusion.scale', 'fusion.zero_point', 'fusion._packed_params.dtype', 'fusion._packed_params._packed_params', 'classifier.2.scale', 'classifier.2.zero_point', 'classifier.2._packed_params.dtype', 'classifier.2._packed_params._packed_params', 'classifier.4.scale', 'classifier.4.zero_point', 'classifier.4._packed_params.dtype', 'classifier.4._packed_params._packed_params'])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load model from\n",
    "model = torch.load('quantized_model.pth')\n",
    "model.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b4a118f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d1271998",
   "metadata": {},
   "source": [
    "Run this in colab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daf998cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Gradio Demo\n",
    "\n",
    "# #  Set the matplotlib backend BEFORE importing pyplot\n",
    "# # This prevents errors in a server environment like Colab.\n",
    "# import matplotlib\n",
    "# matplotlib.use('Agg')\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# import gradio as gr\n",
    "# import numpy as np # Ensure numpy is imported\n",
    "# import torch # Ensure torch is imported\n",
    "\n",
    "# class_names = ['Normal', 'PVC', 'PAC', 'LBBB', 'RBBB']\n",
    "\n",
    "# def predict_ecg(index):\n",
    "#     # Convert the input from the slider (float) to an integer.\n",
    "#     index = int(index)\n",
    "    \n",
    "#     sample = X_test[index]  # [1080, 2]\n",
    "    \n",
    "#     # Predict\n",
    "#     with torch.no_grad():\n",
    "#         # Ensure model and device are accessible (assuming they are global)\n",
    "#         output = model(torch.FloatTensor(sample).unsqueeze(0).to(device))\n",
    "#         probs = torch.softmax(output, dim=1).cpu().numpy()[0]\n",
    "#         pred = np.argmax(probs)\n",
    "#         confidence = probs[pred]\n",
    "    \n",
    "#     # Visualization\n",
    "#     fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 5))\n",
    "#     ax1.plot(sample[:, 0], color='b', linewidth=1)\n",
    "#     ax1.set_title(\"Lead MLII\")\n",
    "#     ax1.grid(True, alpha=0.3)\n",
    "    \n",
    "#     ax2.plot(sample[:, 1], color='r', linewidth=1)\n",
    "#     ax2.set_title(\"Lead V5\")\n",
    "#     ax2.set_xlabel(\"Samples\")\n",
    "#     ax2.grid(True, alpha=0.3)\n",
    "    \n",
    "#     plt.tight_layout()\n",
    "    \n",
    "#     # Prediction bar\n",
    "#     pred_fig, pred_ax = plt.subplots(figsize=(8, 3))\n",
    "#     bars = pred_ax.bar(class_names, probs, \n",
    "#                       color=['red' if i == pred else 'skyblue' for i in range(5)])\n",
    "#     pred_ax.set_title(f\"Prediction: {class_names[pred]} ({confidence:.1%})\")\n",
    "#     pred_ax.axhline(y=0.6, color='orange', linestyle='--', label='Retrain Threshold')\n",
    "#     pred_ax.legend()\n",
    "#     pred_ax.set_ylabel(\"Probability\")\n",
    "    \n",
    "#     status = \"Retraining needed\" if confidence < 0.6 else \"Confident prediction\"\n",
    "    \n",
    "#     # Close figures to prevent memory leaks.\n",
    "#     # We return the figure objects, Gradio renders them, then they can be closed.\n",
    "#     # Note: For simplicity and to ensure it works, we can defer this, but it's good practice.\n",
    "#     # A robust way is to close all figures at the end.\n",
    "#     # plt.close('all') \n",
    "#     # For now, let's return them directly as the main fixes were #1 and #2.\n",
    "\n",
    "#     return fig, pred_fig, f\"{confidence:.1%}\", status\n",
    "\n",
    "# interface = gr.Interface(\n",
    "#     fn=predict_ecg,\n",
    "#     inputs=gr.Slider(0, len(X_test)-1, step=1, label=\"ECG Sample Index\"),\n",
    "#     outputs=[\n",
    "#         gr.Plot(label=\"ECG Signals\"), \n",
    "#         gr.Plot(label=\"Prediction\"),\n",
    "#         gr.Textbox(label=\"Confidence\"), \n",
    "#         gr.Textbox(label=\"Status\")\n",
    "#     ],\n",
    "#     title=\"Adaptive ECG Anomaly Detector\",\n",
    "#     description=\"Hybrid CNN-Transformer with dynamic retraining & quantization.\",\n",
    "#     examples=[[0], [100], [500], [1000]]\n",
    "# )\n",
    "\n",
    "# # Use debug=True to see detailed errors in the Colab console\n",
    "# interface.launch(debug=True, share=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "661876e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8b1de68",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
